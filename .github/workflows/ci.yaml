name: dev-build
on:
  push:
  pull_request:

concurrency:
  group: ${{ github.workflow }}-${{ github.job }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unix:
    strategy:
      matrix:
        include:
          - os: ubuntu-latest
            build_type: Release
          - os: ubuntu-latest
            build_type: Debug
          - os: macos-latest
            build_type: Release

      fail-fast: false
    runs-on: ${{ matrix.os }}

    steps:

      - uses: actions/checkout@v3

      - name: Get number of CPU cores
        uses: SimenB/github-actions-cpu-cores@v1
        id: cpu-cores

      - name: Install Conda environment from environment.yml
        uses: mamba-org/setup-micromamba@v1
        with:
          environment-file: environment.yml
          init-shell: >-
            bash
          cache-environment: true
          post-cleanup: 'all'


      - name: cmake configure
        shell: bash -l {0}
        run: |
          mkdir -p bld
          cd bld
          cmake \
              -DCMAKE_BUILD_TYPE=${{ matrix.build_type }} \
              -DBUILD_TESTS=ON \
              -DBUILD_SINGLE_BINARY_TESTS=ON \
              -DBUILD_PYTHON=ON \
              -DBUILD_DOCS=ON \
          .. -DCMAKE_INSTALL_PREFIX=$CONDA_PREFIX

      - name: Build
        shell: bash -l {0}
        run: |
          cd bld
          make -j ${{ steps.cpu-cores.outputs.count }}

      # on ubuntu we see sporadic failures of the ilp tests.
      # they manifest in a segfault **after** the test has finished
      # without error.
      # The error is in some exit handler and hard to debug =/
      # Therefore we ran on ubuntu with until-pass up to 5 times
      - name: Run C++ tests  via ctest
        if: ${{ matrix.os == 'ubuntu-latest' }}
        shell: bash -l {0}
        run: |
            cd bld
            ctest --repeat until-pass:5 --output-on-failure -R nxtgm_test

      # on macos we **have not** seen the same issue as on ubuntu
      # therefore we the test up to 5 times (
      # there is a small chance that the test fails 5 times in a row
      # but this is very unlikely. If this will happen we will
      # need to change something here)
      - name: Run C++ tests  via ctest
        if: ${{ matrix.os == 'macos-latest' }}
        shell: bash -l {0}
        run: |
            cd bld
            ctest --repeat until-fail:5 --output-on-failure -R nxtgm_test

      # on ubuntu and mac we **do not have any issue** with the ilp tests
      # therefore we all tests except the ilp tests for many times
      - name: Run C++ tests directly and many times but **without** ilp-tests
        shell: bash -l {0}
        run: |
            cd bld
            for i in {1..10}; do echo "run $i";  NXTGM_PLUGIN_PATH=src/nxtgm/plugins ./tests/nxtgm_test_all --tce="ilp*"; done

      # same as above but with random test order
      - name: Run C++ tests directly and many times but **without** ilp-tests
        shell: bash -l {0}
        run: |
            cd bld
            for i in {1..10}; do echo "run $i";  NXTGM_PLUGIN_PATH=src/nxtgm/plugins ./tests/nxtgm_test_all --tce="ilp*" --order-by=random --rand-seed=$i; done


      # at the moment the ilp highs tests are not stable enough and already leak
      # when loading the shared library. Therefore we skip them for now
      - name: Run C++ tests with valgrind
        if: ${{ matrix.os == 'ubuntu-latest' && matrix.build_type == 'Debug' }}
        shell: bash -l {0}
        run: |
            sudo apt install -y libc6-dbg
            $MAMBA_EXE install -y valgrind
            cd bld
            NXTGM_PLUGIN_PATH=src/nxtgm/plugins valgrind --error-exitcode=1 --tool=memcheck --leak-check=full ./tests/nxtgm_test_all --tce="ilp*"


      - name: Run Python tests
        shell: bash -l {0}
        run: |
            cd bld
            ctest --output-on-failure -R python

      - name: install
        shell: bash -l {0}
        run: |
            cd bld
            make install

      - name: run tests from installed binaries / libraries
        if: ${{ matrix.os == 'macos-latest' }}
        shell: bash -l {0}
        run: |
          nxtgm_test_all

      - name: run tests from installed binaries / libraries
        if: ${{ matrix.os == 'ubuntu-latest' }}
        shell: bash -l {0}
        run: |
          nxtgm_test_all --tce="ilp*"

      - name: Build docs
        shell: bash -l {0}
        run: |
            cd bld
            make docs

  windows:
    strategy:
      matrix:
        os: [windows-latest]
        build_type: ["Release", "Debug"]
      fail-fast: false
    runs-on: ${{ matrix.os }}

    steps:

      - uses: actions/checkout@v3

      - name: Install Conda environment from environment.yml
        uses: mamba-org/setup-micromamba@v1
        with:
          environment-file: environment.yml
          init-shell: >-
            cmd.exe
          cache-environment: true
          post-cleanup: 'all'

      - name: build and test
        shell: cmd /C CALL {0}
        run: |

          mkdir bld
          cd bld
          set PATH=%PATH%;%CD%
          cmake .. ^
            -G Ninja ^
            -DCMAKE_BUILD_TYPE=${{ matrix.build_type }} ^
            -DBUILD_TESTS=ON ^
            -DBUILD_SINGLE_BINARY_TESTS=ON ^
            -DBUILD_PYTHON=ON ^
            -DBUILD_DOCS=OFF ^
            -DCMAKE_PREFIX_PATH="%CONDA_PREFIX%\Library" ^
            -DCMAKE_INSTALL_PREFIX="%CONDA_PREFIX%
          cmake --build . --config ${{ matrix.build_type }}
          cmake --install . --config ${{ matrix.build_type }}

      - name: run tests from installed binaries / libraries
        shell: cmd /C CALL {0}
        run: |
          nxtgm_test_all

      # same as abvoe but repeat 10 times with random test order
      - name: run tests from installed binaries / libraries
        shell: cmd /C CALL {0}
        run: |
          for /L %%i in (1,1,10) do (
            nxtgm_test_all --order-by=random --rand-seed=%%i
          )

      # run the tests many times to see if we can reproduce the segfaults
      - name: run C++ tests
        shell: cmd /C CALL {0}
        run: |
          cd bld
          ctest --repeat until-fail:10 --output-on-failure  -R nxtgm_test

      - name: run Python tests
        shell: cmd /C CALL {0}
        run: |
          cd bld
          ctest --output-on-failure  -R python
